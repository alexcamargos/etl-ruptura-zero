# Projeto "Ruptura Zero": An√°lise de Vendas e Estoque

> _Um pipeline de ETL robusto para transformar dados de vendas em insights acion√°veis, diagnosticando rupturas de estoque e otimizando o invent√°rio._

[![LinkedIn](https://img.shields.io/badge/%40alexcamargos-230A66C2?style=social&logo=LinkedIn&label=LinkedIn&color=white)](https://www.linkedin.com/in/alexcamargos)

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python Version](https://img.shields.io/badge/Python-3.11%2B-blue.svg)](https://www.python.org/downloads/)


## üí° Sobre o Projeto
O "Ruptura Zero" √© um pipeline de ETL desenvolvido em Python para diagnosticar a causa raiz da queda de vendas em uma empresa. O projeto nasceu da hip√≥tese de que a m√° gest√£o de invent√°rio estava gerando ruptura de estoque (falta de produtos), impactando diretamente a receita.

Este pipeline automatiza a extra√ß√£o de dados brutos de vendas e estoque de arquivos Excel, aplica um rigoroso processo de limpeza e transforma√ß√£o, e utiliza `Pandera` para garantir a integridade dos dados. O resultado final √© um dataset consolidado e confi√°vel, pronto para an√°lise, permitindo que a √°rea de neg√≥cio identifique exatamente quais produtos est√£o em falta e onde, transformando dados em um plano de a√ß√£o para otimiza√ß√£o de invent√°rio e recupera√ß√£o do crescimento.


- [Projeto "Ruptura Zero": An√°lise de Vendas e Estoque](#projeto-ruptura-zero-an√°lise-de-vendas-e-estoque)
  - [üí° Sobre o Projeto](#-sobre-o-projeto)
  - [üõ†Ô∏è Stack de Tecnologias](#Ô∏è-stack-de-tecnologias)
  - [‚ú® Funcionalidades Principais](#-funcionalidades-principais)
  - [üèõÔ∏è Arquitetura e Padr√µes](#Ô∏è-arquitetura-e-padr√µes)
  - [üöÄ Como Instalar e Executar](#-como-instalar-e-executar)
  - [üìä Resultados e Entreg√°veis](#-resultados-e-entreg√°veis)
  - [üß† Desafios T√©cnicos e Aprendizados](#-desafios-t√©cnicos-e-aprendizados)
    - [1. Garantia da Qualidade dos Dados para Confian√ßa no Resultado](#1-garantia-da-qualidade-dos-dados-para-confian√ßa-no-resultado)
    - [2. Controle e Manutenibilidade do Fluxo de ETL](#2-controle-e-manutenibilidade-do-fluxo-de-etl)
    - [3. Habilita√ß√£o de An√°lises Complexas e Acesso aos Dados](#3-habilita√ß√£o-de-an√°lises-complexas-e-acesso-aos-dados)
    - [4. Transformando um Script de Dados em um Produto de Software](#4-transformando-um-script-de-dados-em-um-produto-de-software)
  - [üöÄ Pr√≥ximos Passos](#-pr√≥ximos-passos)
  - [‚úçÔ∏è Autor](#Ô∏è-autor)
  - [üìú Licen√ßa](#-licen√ßa)


## üõ†Ô∏è Stack de Tecnologias
| Categoria | Ferramenta |
| :--- | :--- |
| **Gerenciador de Depend√™ncias** | ![UV](https://img.shields.io/badge/uv-0.1.11-purple?style=flat-square) |
| **Linguagem Principal** | ![Python](https://img.shields.io/badge/Python-3.11%2B-blue?style=flat-square&logo=python) |
| **An√°lise de Dados** | ![Pandas](https://img.shields.io/badge/Pandas-2.3.2-blue?style=flat-square&logo=pandas) ![NumPy](https://img.shields.io/badge/NumPy-2.0.2-blue?style=flat-square&logo=numpy) |
| **Valida√ß√£o de Dados** | ![Pandera](https://img.shields.io/badge/Pandera-0.14.5-blue?style=flat-square) |
| **Data Warehouse** | ![DuckDB](https://img.shields.io/badge/DuckDB-FFF000?style=flat-square&logo=duckdb&logoColor=black) ![MotherDuck](https://img.shields.io/badge/MotherDuck-000000?style=flat-square&logo=motherduck) |


## ‚ú® Funcionalidades Principais
- **üîå Extra√ß√£o de Dados**: Leitura e parsing de m√∫ltiplas fontes de dados em formato `.xlsx`.
- **üßπ Limpeza e Transforma√ß√£o**: Normaliza√ß√£o de formatos, tratamento de valores nulos e enriquecimento de dados.
- **üõ°Ô∏è Valida√ß√£o Robusta**: Implementa√ß√£o de esquemas `Pandera` para garantir a qualidade e a consist√™ncia dos dados em cada etapa.
- **üìä An√°lise e Agrega√ß√£o**: Cruzamento de tabelas de vendas e estoque para o c√°lculo preciso de m√©tricas de ruptura.
- **üì§ Carga de Dados**: Exporta√ß√£o dos dados processados para arquivos `.csv` e carga em um data warehouse serverless **MotherDuck** para an√°lise SQL imediata.


## üèõÔ∏è Arquitetura e Padr√µes
O projeto segue um fluxo de dados desacoplado, utilizando o padr√£o Factory para orquestrar as etapas de Extra√ß√£o, Transforma√ß√£o e Carga, garantindo manutenibilidade e escalabilidade.

![Diagrama de Arquitetura do ETL Ruptura Zero](references/fluxograma.png)

- **/ruptura_zero/extractor**: M√≥dulos respons√°veis pela extra√ß√£o de dados de fontes externas (ex: planilhas Excel).
- **/ruptura_zero/transformer**: Cont√©m a l√≥gica de neg√≥cio para limpeza, transforma√ß√£o e valida√ß√£o dos dados. Utiliza **Pandera** para definir e aplicar esquemas de valida√ß√£o, garantindo a robustez do pipeline.
- **/ruptura_zero/services**: Orquestra as etapas limpesa e transforma√ß√£o do pipeline, desacoplando do pipeline principal o status de cada etapa.
- **/ruptura_zero/loader**: Respons√°vel por carregar os dados transformados em um destino final, arquivos CSV consolidados e data warehouse na nuvem (MotherDuck).
- **/ruptura_zero/factory.py**: Aplica o padr√£o de projeto **Factory** para criar inst√¢ncias de componentes do pipeline de forma desacoplada.

Essa arquitetura modular e o uso de valida√ß√£o de dados demonstram um foco em criar um sistema de dados confi√°vel e escal√°vel.


## üöÄ Como Instalar e Executar

**Pr√©-requisitos:**
- Python 3.11 ou superior
- `uv` instalado (`pip install uv`)

**Passos:**

1.  Clone o reposit√≥rio:
    ```bash
    git clone https://github.com/alexcamargos/etl_ruptura_zero.git
    cd etl_ruptura_zero
    ```

2.  Crie e ative um ambiente virtual:
    ```bash
    uv venv
    source .venv/bin/activate  # No Windows: .venv\Scripts\activate
    ```

3.  Instale as depend√™ncias do projeto:
    ```bash
    uv pip sync pyproject.toml
    ```

4.  Execute o pipeline de ETL:
    ```bash
    python main.py
    # Ao final da execu√ß√£o, verifique a pasta `data/processed/` pelos arquivos gerados.
    ```

## üìä Resultados e Entreg√°veis
Ao final da execu√ß√£o, o pipeline produz dois tipos de entreg√°veis, prontos para diferentes casos de uso:

**1. Arquivos CSV Consolidados**
Para an√°lise local, portabilidade ou importa√ß√£o r√°pida em outras ferramentas, os seguintes arquivos s√£o gerados na pasta `data/processed/`:
- `ruptura_estoque_vendas.csv`: O dataset final consolidado, contendo a uni√£o dos dados de vendas e estoque.

**2. Data Warehouse na Nuvem (MotherDuck)**
Para an√°lise interativa e escal√°vel, o dataset consolidado √© carregado em uma tabela no MotherDuck. Isso o torna imediatamente acess√≠vel para:
- Consultas complexas usando SQL.
- Conex√£o direta com ferramentas de Business Intelligence (BI) como Tableau ou Power BI.


## üß† Desafios T√©cnicos e Aprendizados

A constru√ß√£o deste pipeline foi uma jornada de aprendizado em engenharia de dados, focada em robustez, manutenibilidade e valor de neg√≥cio.

### 1. Garantia da Qualidade dos Dados para Confian√ßa no Resultado
- **O Problema:** A fonte de dados (planilhas Excel) era um ambiente din√¢mico e pouco confi√°vel. Inconsist√™ncias como tipos de dados errados, nomes de colunas alterados ou valores nulos inesperados poderiam corromper silenciosamente o resultado final, gerando an√°lises incorretas e quebrando a confian√ßa dos stakeholders.
- **A Solu√ß√£o:** Em vez de criar valida√ß√µes manuais reativas, implementei uma estrat√©gia proativa usando **Pandera** para definir "contratos de dados" (Data Contracts). Cada DataFrame, ao entrar e sair de uma etapa de transforma√ß√£o, √© validado contra um esquema rigoroso. Se o contrato for violado, o pipeline falha de forma expl√≠cita e imediata, impedindo a propaga√ß√£o de dados de baixa qualidade.
- **O Aprendizado:** Compreendi que a qualidade dos dados n√£o √© uma etapa, mas uma garantia cont√≠nua. Adotar uma abordagem de "Data Quality as Code" com Pandera tornou o pipeline n√£o apenas mais robusto, mas tamb√©m autodocumentado, onde os esquemas servem como uma fonte √∫nica de verdade sobre a estrutura dos dados.

### 2. Controle e Manutenibilidade do Fluxo de ETL
- **O Problema:** Um script monol√≠tico que executa extra√ß√£o, transforma√ß√£o e carga em sequ√™ncia √© fr√°gil e dif√≠cil de manter. Alterar a fonte de dados ou adicionar uma nova regra de neg√≥cio exigiria uma refatora√ß√£o arriscada e complexa.
- **A Solu√ß√£o:** Estruturei o c√≥digo aplicando princ√≠pios SOLID e o padr√£o de projeto **Factory**. Cada etapa do ETL (Extract, Transform, Load) foi isolada em seu pr√≥prio m√≥dulo com responsabilidades claras. A factory `build_application` orquestra a execu√ß√£o, injetando as depend√™ncias corretas sem que o orquestrador conhe√ßa os detalhes de implementa√ß√£o de cada componente.
- **O Aprendizado:** Esta arquitetura me ensinou na pr√°tica o valor do baixo acoplamento e da alta coes√£o. O sistema tornou-se modular, test√°vel e extens√≠vel. Agora, para suportar uma nova fonte de dados (ex: um banco de dados), basta criar uma nova classe `Extractor` sem impactar o resto da aplica√ß√£o, demonstrando a import√¢ncia de design patterns para a escalabilidade de projetos de dados.

### 3. Habilita√ß√£o de An√°lises Complexas e Acesso aos Dados
- **O Problema:** Gerar um arquivo CSV como resultado final resolve a consolida√ß√£o, mas cria um novo problema: os dados ficam "presos" em um arquivo est√°tico. Para qualquer an√°lise mais profunda, um usu√°rio precisaria realizar um processo manual de download e importa√ß√£o em outra ferramenta, atrasando a gera√ß√£o de insights.
- **A Solu√ß√£o:** Integrei uma etapa de carga final para um data warehouse em nuvem, o **MotherDuck**. Ap√≥s o processamento, o dataset limpo e consolidado √© carregado diretamente em uma tabela otimizada para an√°lises.
- **O Aprendizado:** Entendi que o objetivo de um pipeline de ETL n√£o √© apenas "mover e limpar dados", mas sim reduzir o "tempo-para-insight" (time-to-insight). Ao disponibilizar os dados em uma plataforma anal√≠tica como o MotherDuck, o resultado do pipeline se torna um ativo de dados vivo e imediatamente acion√°vel por analistas e ferramentas de BI via SQL, agregando muito mais valor ao neg√≥cio do que um simples arquivo CSV.

### 4. Transformando um Script de Dados em um Produto de Software
- **O Problema:** Um pipeline de dados pode facilmente se tornar um "script" longo e de dif√≠cil manuten√ß√£o. Sem uma estrutura definida, gerenciamento de depend√™ncias e padr√µes de qualidade, o projeto se torna fr√°gil, dif√≠cil de testar e quase imposs√≠vel de ser mantido ou expandido por outra pessoa.
- **A Solu√ß√£o:** Abordei a constru√ß√£o do pipeline aplicando um conjunto rigoroso de pr√°ticas de engenharia de software desde o in√≠cio:
    - **Estrutura de Projeto Modular:** O c√≥digo foi organizado em m√≥dulos com responsabilidades √∫nicas (`extractor`, `transformer`, `loader`), facilitando a navega√ß√£o e a manuten√ß√£o.
    - **Gerenciamento de Depend√™ncias Moderno:** Utilizei `pyproject.toml` e `uv` para garantir um ambiente de desenvolvimento 100% reprodut√≠vel e isolado, eliminando o problema de "funciona na minha m√°quina".
    - **Qualidade e Estilo de C√≥digo:** Adotei ferramentas de linting e formata√ß√£o (como `Ruff` e `Black`) para manter um padr√£o de c√≥digo consistente e leg√≠vel em todo o projeto.
    - **Separa√ß√£o de Configura√ß√£o e L√≥gica:** Par√¢metros como caminhos de arquivos e configura√ß√µes foram externalizados, permitindo que o pipeline seja executado em diferentes ambientes sem alterar o c√≥digo-fonte.
- **O Aprendizado:** O aprendizado fundamental foi **tratar o pipeline de dados como um produto de software, n√£o como um script descart√°vel**. Aplicar essas pr√°ticas aumenta a confian√ßa no sistema, acelera o desenvolvimento de novas funcionalidades e garante que o projeto seja robusto e escal√°vel o suficiente para ser colocado em produ√ß√£o.


## üöÄ Pr√≥ximos Passos
Este projeto √© uma base s√≥lida, e os pr√≥ximos passos planejados para evolu√≠-lo incluem:
- [ ] **Dashboard Interativo com Streamlit**: Desenvolver um painel visual para apresentar os resultados da an√°lise de ruptura, permitindo que usu√°rios de neg√≥cio explorem os dados e respondam √† pergunta central do projeto de forma interativa.
- [ ] **Testes Automatizados**: Implementar testes unit√°rios com `pytest` para as regras de neg√≥cio e de transforma√ß√£o.
- [ ] **Containeriza√ß√£o com Docker**: Empacotar a aplica√ß√£o para garantir a reprodutibilidade do ambiente e facilitar o deploy.
- [ ] **Orquestra√ß√£o de Workflow**: Migrar a execu√ß√£o para uma ferramenta como Mage ou Airflow para agendamento, monitoramento e retentativas.


## ‚úçÔ∏è Autor

Feito com ‚ù§Ô∏è por [Alexsander Lopes Camargos](https://github.com/alexcamargos) üëã Entre em contato!

[![GitHub](https://img.shields.io/badge/-AlexCamargos-1ca0f1?style=flat-square&labelColor=1ca0f1&logo=github&logoColor=white&link=https://github.com/alexcamargos)](https://github.com/alexcamargos)
[![Twitter Badge](https://img.shields.io/badge/-@alcamargos-1ca0f1?style=flat-square&labelColor=1ca0f1&logo=twitter&logoColor=white&link=https://twitter.com/alcamargos)](https://twitter.com/alcamargos)
[![Linkedin Badge](https://img.shields.io/badge/-alexcamargos-1ca0f1?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/alexcamargos/)](https://www.linkedin.com/in/alexcamargos/)
[![Gmail Badge](https://img.shields.io/badge/-alcamargos@vivaldi.net-1ca0f1?style=flat-square&labelColor=1ca0f1&logo=Gmail&logoColor=white&link=mailto:alcamargos@vivaldi.net)](mailto:alcamargos@vivaldi.net)


## üìú Licen√ßa
Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
